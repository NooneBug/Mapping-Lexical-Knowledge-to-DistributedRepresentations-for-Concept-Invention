{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mixed_regression_functions import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = {'4': [], '8' : []}\n",
    "with open('/datahdd/vmanuel/ELMo/Corpora/40k_dbpedia_sentences.txt', 'r') as inp:\n",
    "    lines['4'] = inp.readlines()\n",
    "    lines['4'] = [l.split() for l in lines['4']]\n",
    "    \n",
    "with open('/datahdd/vmanuel/ELMo/Corpora/80k_dbpedia_sentences.txt', 'r') as inp:\n",
    "    lines['8'] = inp.readlines()\n",
    "    lines['8'] = [l.split() for l in lines['8']]\n",
    "\n",
    "liness = []\n",
    "liness = lines['4']\n",
    "liness.extend(lines['8'])\n",
    "len(liness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve all URI and preprocess them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sons_of = {}\n",
    "\n",
    "sons_of['Activity'] = ['Sport'\n",
    "#                       ,'Game' \n",
    "                      ]\n",
    "sons_of['Agent'] = ['FictionalCharacter']\n",
    "sons_of['Organisation'] = ['Company'\n",
    "#                            , 'EducationalInstitution', 'GovernmentAgency', 'PoliticalParty', 'SportsLeague'\n",
    "                           , 'SportsTeam']\n",
    "sons_of['Thing'] = [\n",
    "#     'AnatomicalStructure', \n",
    "                    'Award', 'Colour'\n",
    "                    ,'EthnicGroup', 'Language', 'Plant'\n",
    "#                     , 'Currency'\n",
    "                    ,'Weapon']\n",
    "sons_of['Place'] = ['ArchitecturalStructure', 'Planet']\n",
    "sons_of['Animal'] = ['Bird'\n",
    "#                      , 'Crustacean'\n",
    "#                      , 'Fish', 'Amphibian' \n",
    "                     , 'Insect', 'Mammal'\n",
    "#                      , 'Mollusca', 'Reptile'\n",
    "                    ]\n",
    "# sons_of['Person'] = ['Artist', 'Scientist'\n",
    "#                     ,'Athlete', 'Writer'\n",
    "#                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['dbo:' + s for sublist in sons_of.values() for s in sublist]\n",
    "\n",
    "classes = [x.replace('dbo:', '') for x in types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "i = 0\n",
    "for t in types:\n",
    "    w = get_from_class(t)\n",
    "    words.append(w) \n",
    "    clear_output()\n",
    "    i += 1\n",
    "    print(round(i/len(types), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_words = {c: [] for c in classes}\n",
    "regex = re.compile(\".*?\\((.*?)\\)\")\n",
    "\n",
    "\n",
    "for i, w_list in enumerate(words):\n",
    "    for w in w_list:\n",
    "        w = re.sub(r'\\([^)]*\\)', '', w).strip()\n",
    "        w = w.replace(\"'\", \"\")\n",
    "        \n",
    "        if len(w.split('_')) == 2 and len(w.split('-')) < 2:\n",
    "            if '' not in w.lower().split('_'):\n",
    "                comp_words[classes[i]].append(w.lower().split('_'))\n",
    "        elif len(w.split('-')) == 2 and len(w.split('_')) < 2:\n",
    "            if '' not in w.lower().split('-'):\n",
    "                comp_words[classes[i]].append(w.lower().split('-'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44359"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = re.compile('^[A-z]*$')\n",
    "word_to_index = set([s for sublists in comp_words.values() for sublist in sublists for s in sublist if re.search(alpha, s) and s != ''])\n",
    "len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comp_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79900\n"
     ]
    }
   ],
   "source": [
    "word_index = {}\n",
    "for i, line in enumerate(liness):\n",
    "    for word in line:\n",
    "        if word in word_to_index:\n",
    "            try:\n",
    "                word_index[word].append(i)\n",
    "            except:\n",
    "                word_index[word] = [i]\n",
    "    if i % 100 == 0:\n",
    "        clear_output()\n",
    "        print(i)\n",
    "word_index = {k:set(v) for k,v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_word_indexes = {c: [] for c in classes}\n",
    "for k, typelist in comp_words.items():\n",
    "    for couple in typelist:\n",
    "        try:\n",
    "            inter = word_index[couple[0]].intersection(word_index[couple[1]])\n",
    "            if inter:\n",
    "                comp_word_indexes[k].append([couple, list(inter)])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "real_couples_indexes = {}\n",
    "tot = len(comp_word_indexes.values())\n",
    "j = 0\n",
    "for k, v in comp_word_indexes.items():\n",
    "    for couple in v:\n",
    "        for index in couple[1]:\n",
    "            if abs(liness[index].index(couple[0][0]) - \n",
    "                   liness[index].index(couple[0][1])) == 1:\n",
    "                try:\n",
    "                    real_couples_indexes[\"{}_{}\".format(couple[0][0], couple[0][1])].append([\n",
    "                        [liness[index].index(couple[0][0]), liness[index].index(couple[0][1])],\n",
    "                        index])\n",
    "                except:\n",
    "                    real_couples_indexes[\"{}_{}\".format(couple[0][0], couple[0][1])] = [k, \n",
    "                                                                                        [\n",
    "                                                                                            [liness[index].index(couple[0][0]), \n",
    "                                                                                             liness[index].index(couple[0][1])],\n",
    "                                                                                            index]]\n",
    "    j += 1\n",
    "    clear_output()\n",
    "    print(round(j/tot, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_data_with_pickle(relative_path, data):\n",
    "    \"\"\" Save data using pickle (serialize) \"\"\"\n",
    "\n",
    "    with open(relative_path, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_with_pickle('/datahdd/vmanuel/datasets/composite_words_index', real_couples_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
